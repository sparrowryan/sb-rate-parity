name: Weekly Rate Tracker
on:
  # Runs every Monday at 8:05 UTC
  schedule:
    - cron: "5 8 * * 1"
  # Allows you to run it manually from the Actions tab
  workflow_dispatch:

jobs:
  run:
    runs-on: ubuntu-latest

    steps:
      # 1. Pull the repo contents
      - name: Checkout repository
        uses: actions/checkout@v4

      # 2. Set up Node
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      # 3. Install dependencies (works even if no package-lock.json)
      - name: Install dependencies
        run: |
          echo "Installing npm packages..."
          npm install

      # 4. Install Playwright browsers & dependencies
      - name: Install Playwright
        run: npx playwright install --with-deps

      # 5. Optional: quick test to ensure the webhook works before scraping
      - name: Webhook smoke test
        run: |
          node -e "
            import('node-fetch').then(({default:fetch}) =>
              fetch(process.env.WEBHOOK_URL,{
                method:'POST',
                headers:{'Content-Type':'application/json'},
                body:JSON.stringify({
                  rows:[[
                    new Date().toISOString().slice(0,10),
                    '2025-11-07','2025-11-09',
                    'Smoke Test Hotel','City',
                    200,220,225,230,240,235,245,
                    20,20/220,
                    'https://sparrowbid.com',
                    'https://google.com/travel/hotels'
                  ]]
                })
              }).then(r=>r.text()).then(t=>console.log('Webhook response:',t))
            );
          "
        env:
          WEBHOOK_URL: ${{ secrets.WEBHOOK_URL }}

      # 6. Run the actual scraper
      - name: Run scraper
        run: node index.js
        env:
          WEBHOOK_URL: ${{ secrets.WEBHOOK_URL }}
          CHECKIN_OFFSET_DAYS: 7
          NIGHTS: 2
